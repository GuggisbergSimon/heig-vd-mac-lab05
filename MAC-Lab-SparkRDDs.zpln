{
  "paragraphs": [
    {
      "text": "%md\n# Méthode d'accès aux données\n## Labo: Spark\n\nAuteur: Christopher MEIER\n\nPrintemps 2024",
      "user": "anonymous",
      "dateUpdated": "2024-05-24T08:08:05+0000",
      "progress": 0,
      "config": {
        "lineNumbers": true,
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "colWidth": 12,
        "editorHide": true,
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h1>Méthode d&rsquo;accès aux données</h1>\n<h2>Labo: Spark</h2>\n<p>Auteur: Christopher MEIER</p>\n<p>Printemps 2024</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1716538085685_1113324013",
      "id": "20240513-092648_2102106332",
      "dateCreated": "2024-05-24T08:08:05+0000",
      "status": "READY",
      "focus": true,
      "$$hashKey": "object:183"
    },
    {
      "text": "%md\n### Spark initialisation\n\nNothing to modify in this section.\n\nHere we create and configure the SparkSession and SparkContext.",
      "user": "anonymous",
      "dateUpdated": "2024-05-24T08:08:05+0000",
      "progress": 0,
      "config": {
        "lineNumbers": true,
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "colWidth": 12,
        "editorHide": true,
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h3>Spark initialisation</h3>\n<p>Nothing to modify in this section.</p>\n<p>Here we create and configure the SparkSession and SparkContext.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1716538085686_1499494468",
      "id": "20240513-092648_713056072",
      "dateCreated": "2024-05-24T08:08:05+0000",
      "status": "READY",
      "$$hashKey": "object:184"
    },
    {
      "text": "%spark\n// The spark session is automatically created by Zeppelin.\n// We import some often used functions\nimport org.apache.spark.sql._\nimport org.apache.spark.rdd._",
      "user": "anonymous",
      "dateUpdated": "2024-05-24T08:22:48+0000",
      "progress": 0,
      "config": {
        "lineNumbers": true,
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "colWidth": 12,
        "editorHide": false,
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "import org.apache.spark.sql._\nimport org.apache.spark.rdd._\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1716538085686_406370195",
      "id": "20240513-092648_753540709",
      "dateCreated": "2024-05-24T08:08:05+0000",
      "status": "FINISHED",
      "$$hashKey": "object:185",
      "dateFinished": "2024-05-24T08:22:48+0000",
      "dateStarted": "2024-05-24T08:22:48+0000"
    },
    {
      "text": "%md\n### Dataset loading\n\nNothing to modify in this section.",
      "user": "anonymous",
      "dateUpdated": "2024-05-24T08:08:05+0000",
      "progress": 0,
      "config": {
        "lineNumbers": true,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "colWidth": 12,
        "editorHide": true,
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h3>Dataset loading</h3>\n<p>Nothing to modify in this section.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1716538085686_1881928164",
      "id": "20240513-092648_1088362509",
      "dateCreated": "2024-05-24T08:08:05+0000",
      "status": "READY",
      "$$hashKey": "object:186"
    },
    {
      "text": "%spark\ncase class Movie(id: Int, title: String, genres: Seq[String],\n                 description: String, director: String, actors: Seq[String],\n                 year: Int, rating: Float, votes: Int)",
      "user": "anonymous",
      "dateUpdated": "2024-05-24T08:22:55+0000",
      "progress": 0,
      "config": {
        "lineNumbers": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "colWidth": 12,
        "editorHide": false,
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "class Movie\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1716538085686_1215642871",
      "id": "20240513-092648_1619176723",
      "dateCreated": "2024-05-24T08:08:05+0000",
      "status": "FINISHED",
      "$$hashKey": "object:187",
      "dateFinished": "2024-05-24T08:22:55+0000",
      "dateStarted": "2024-05-24T08:22:55+0000"
    },
    {
      "text": "%spark\ndef parseRow(row: Row): Movie = {\n    val id = row.getInt(0)\n    val title = row.getString(1)\n    val genres = row.getString(2).split(\",\").toList\n    val description = row.getString(3)\n    val director = row.getString(4)\n    val actors = row.getString(5).split(\",\").toList\n    val year = row.getInt(6)\n    val rating = row.getDouble(8).toFloat\n    val votes = row.getInt(9)\n\n    Movie(id, title, genres, description, director, actors, year, rating, votes)\n}",
      "user": "anonymous",
      "dateUpdated": "2024-05-24T08:23:00+0000",
      "progress": 0,
      "config": {
        "lineNumbers": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "colWidth": 12,
        "editorHide": false,
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "def parseRow(row: org.apache.spark.sql.Row): \u001b[1m\u001b[32mMovie\u001b[0m\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1716538085686_629626227",
      "id": "20240513-092648_876154503",
      "dateCreated": "2024-05-24T08:08:05+0000",
      "status": "FINISHED",
      "$$hashKey": "object:188",
      "dateFinished": "2024-05-24T08:23:00+0000",
      "dateStarted": "2024-05-24T08:23:00+0000"
    },
    {
      "text": "%spark\nval filename = \"/data/IMDB-Movie-Data.csv\"\nval moviesDF = spark.read.format(\"csv\")\n    .option(\"sep\", \",\")\n    .option(\"inferSchema\", \"true\")\n    .option(\"header\", \"true\")\n    .load(filename)\nval rddMovies = moviesDF.rdd.map(parseRow)",
      "user": "anonymous",
      "dateUpdated": "2024-05-24T08:24:41+0000",
      "progress": 0,
      "config": {
        "lineNumbers": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "colWidth": 12,
        "editorHide": false,
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "val \u001b[1m\u001b[34mfilename\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m = /data/IMDB-Movie-Data.csv\nval \u001b[1m\u001b[34mmoviesDF\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [Rank: int, Title: string ... 10 more fields]\nval \u001b[1m\u001b[34mrddMovies\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.rdd.RDD[Movie]\u001b[0m = MapPartitionsRDD[15] at map at <console>:8\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://47152b476fc3:4040/jobs/job?id=0",
              "$$hashKey": "object:2271"
            },
            {
              "jobUrl": "http://47152b476fc3:4040/jobs/job?id=1",
              "$$hashKey": "object:2272"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1716538085686_793970146",
      "id": "20240513-092648_218362564",
      "dateCreated": "2024-05-24T08:08:05+0000",
      "status": "FINISHED",
      "$$hashKey": "object:189",
      "dateFinished": "2024-05-24T08:24:43+0000",
      "dateStarted": "2024-05-24T08:24:41+0000"
    },
    {
      "text": "%spark\n// Print the title of the first 10 movies to see if they were correctly added.\nrddMovies.take(10).map(m => m.title).foreach(println)",
      "user": "anonymous",
      "dateUpdated": "2024-05-24T08:24:48+0000",
      "progress": 0,
      "config": {
        "lineNumbers": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "colWidth": 12,
        "editorHide": false,
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "Guardians of the Galaxy\nPrometheus\nSplit\nSing\nSuicide Squad\nThe Great Wall\nLa La Land\nMindhorn\nThe Lost City of Z\nPassengers\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://47152b476fc3:4040/jobs/job?id=2",
              "$$hashKey": "object:2318"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1716538085686_1156798305",
      "id": "20240513-092648_2138868674",
      "dateCreated": "2024-05-24T08:08:05+0000",
      "status": "FINISHED",
      "$$hashKey": "object:190",
      "dateFinished": "2024-05-24T08:24:48+0000",
      "dateStarted": "2024-05-24T08:24:48+0000"
    },
    {
      "text": "%md\n### Part 1 - Playing with the movies using RDD functions\n\nThe goal of this part is to play (i.e. query, filter and transform the data) with the movies.",
      "user": "anonymous",
      "dateUpdated": "2024-05-24T08:08:05+0000",
      "progress": 0,
      "config": {
        "lineNumbers": true,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "colWidth": 12,
        "editorHide": true,
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h3>Part 1 - Playing with the movies using RDD functions</h3>\n<p>The goal of this part is to play (i.e. query, filter and transform the data) with the movies.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1716538085686_323732278",
      "id": "20240513-092648_182672139",
      "dateCreated": "2024-05-24T08:08:05+0000",
      "status": "READY",
      "$$hashKey": "object:191"
    },
    {
      "text": "%md\n#### Ex1 - Print the movies whose title contains \"City\" \n\nGoal: \n\n* use `map()` and `filter()` methods to get the title of the movies that contains \"City\" in their title\n \nOutput example:\n\n```plain\nCity of Tiny Lights\nThe Mortal Instruments: City of Bones\n```\n\nSteps:\n\n* Use `filter()` to only keep the movies that contains \"City\" in their title\n* Use `map()` to retrieve the titles of these filtered movies\n* Use `foreach()` to pretty print the results",
      "user": "anonymous",
      "dateUpdated": "2024-05-24T08:08:05+0000",
      "progress": 0,
      "config": {
        "lineNumbers": true,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "colWidth": 12,
        "editorHide": true,
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h4>Ex1 - Print the movies whose title contains &ldquo;City&rdquo;</h4>\n<p>Goal:</p>\n<ul>\n<li>use <code>map()</code> and <code>filter()</code> methods to get the title of the movies that contains &ldquo;City&rdquo; in their title</li>\n</ul>\n<p>Output example:</p>\n<pre><code class=\"language-plain\">City of Tiny Lights\nThe Mortal Instruments: City of Bones\n</code></pre>\n<p>Steps:</p>\n<ul>\n<li>Use <code>filter()</code> to only keep the movies that contains &ldquo;City&rdquo; in their title</li>\n<li>Use <code>map()</code> to retrieve the titles of these filtered movies</li>\n<li>Use <code>foreach()</code> to pretty print the results</li>\n</ul>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1716538085686_1457330134",
      "id": "20240513-092648_143829024",
      "dateCreated": "2024-05-24T08:08:05+0000",
      "status": "READY",
      "$$hashKey": "object:192"
    },
    {
      "text": "%spark\nrddMovies.filter(m => m.title.contains(\"City\")).map(m => m.title).collect().foreach(println)\n",
      "user": "anonymous",
      "dateUpdated": "2024-05-24T08:42:20+0000",
      "progress": 0,
      "config": {
        "lineNumbers": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "colWidth": 12,
        "editorHide": false,
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "The Lost City of Z\nSin City: A Dame to Kill For\nCity of Tiny Lights\nThe Mortal Instruments: City of Bones\nSex and the City\nSex and the City 2\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://47152b476fc3:4040/jobs/job?id=9",
              "$$hashKey": "object:2899"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1716538085687_1934556890",
      "id": "20240513-092648_1913578715",
      "dateCreated": "2024-05-24T08:08:05+0000",
      "status": "FINISHED",
      "$$hashKey": "object:193",
      "dateFinished": "2024-05-24T08:42:20+0000",
      "dateStarted": "2024-05-24T08:42:20+0000"
    },
    {
      "text": "%md\n#### Ex2 - Print the title of the movies rated between `rateMin` and `rateMax`. Take the 10 best ratings.\n\nGoal:\n    \n* Take the titles of the movies that were rated between `rateMin` and `rateMax` (excluding `rateMin` and including`rateMax`).\n* This list is sorted by rating DESC\n    \nOutput example:\n\n```plain\n...\n3.7 - The Last Face\n3.5 - Wrecker\n...\n```\n    \nSteps:\n\n* Use `filter()` to only keep the movies released between `rateMin` and `rateMax`\n* Sort the filtered movies by decreasing rating\n* Use `map()` to keep only the relevant attributes (i.e. rating and title)\n* Use `foreach()` to pretty print the results",
      "user": "anonymous",
      "dateUpdated": "2024-05-24T08:08:05+0000",
      "progress": 0,
      "config": {
        "lineNumbers": true,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "colWidth": 12,
        "editorHide": true,
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h4>Ex2 - Print the title of the movies rated between <code>rateMin</code> and <code>rateMax</code>. Take the 10 best ratings.</h4>\n<p>Goal:</p>\n<ul>\n<li>Take the titles of the movies that were rated between <code>rateMin</code> and <code>rateMax</code> (excluding <code>rateMin</code> and including<code>rateMax</code>).</li>\n<li>This list is sorted by rating DESC</li>\n</ul>\n<p>Output example:</p>\n<pre><code class=\"language-plain\">...\n3.7 - The Last Face\n3.5 - Wrecker\n...\n</code></pre>\n<p>Steps:</p>\n<ul>\n<li>Use <code>filter()</code> to only keep the movies released between <code>rateMin</code> and <code>rateMax</code></li>\n<li>Sort the filtered movies by decreasing rating</li>\n<li>Use <code>map()</code> to keep only the relevant attributes (i.e. rating and title)</li>\n<li>Use <code>foreach()</code> to pretty print the results</li>\n</ul>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1716538085687_1088704228",
      "id": "20240513-092648_847272060",
      "dateCreated": "2024-05-24T08:08:05+0000",
      "status": "READY",
      "$$hashKey": "object:194"
    },
    {
      "text": "%spark\nval rateMin = 3\nval rateMax = 4\nval movieRatingsAndTitles = rddMovies.filter(m => m.rating > rateMin && m.rating <= rateMax).sortBy(m => -m.rating).map(m => (m.rating, m.title)).collect()\nmovieRatingsAndTitles.foreach { case (rating, title) =>\n  println(s\"$rating - $title\")\n}\n",
      "user": "anonymous",
      "dateUpdated": "2024-05-24T09:07:21+0000",
      "progress": 0,
      "config": {
        "lineNumbers": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "colWidth": 12,
        "editorHide": false,
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "4.0 - 2307: Winter's Dream\n3.9 - The Disappointments Room\n3.9 - The Black Room\n3.9 - Birth of the Dragon\n3.7 - The Last Face\n3.7 - Satanic\n3.5 - The Intent\n3.5 - Wrecker\n3.2 - Tall Men\nval \u001b[1m\u001b[34mrateMin\u001b[0m: \u001b[1m\u001b[32mInt\u001b[0m = 3\nval \u001b[1m\u001b[34mrateMax\u001b[0m: \u001b[1m\u001b[32mInt\u001b[0m = 4\nval \u001b[1m\u001b[34mmovieRatingsAndTitles\u001b[0m: \u001b[1m\u001b[32mArray[(Float, String)]\u001b[0m = Array((4.0,2307: Winter's Dream), (3.9,The Disappointments Room), (3.9,The Black Room), (3.9,Birth of the Dragon), (3.7,The Last Face), (3.7,Satanic), (3.5,The Intent), (3.5,Wrecker), (3.2,Tall Men))\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://47152b476fc3:4040/jobs/job?id=14",
              "$$hashKey": "object:3244"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1716538085687_2039990604",
      "id": "20240513-092648_415273231",
      "dateCreated": "2024-05-24T08:08:05+0000",
      "status": "FINISHED",
      "$$hashKey": "object:195",
      "dateFinished": "2024-05-24T09:07:21+0000",
      "dateStarted": "2024-05-24T09:07:21+0000"
    },
    {
      "text": "%md\n#### Ex3 - Print the 10 top genres\n\nGoals:\n\n* Print the list of the genres that appears the most\n* Use `flatMap()`\n\nOutput example:\n\n```plain\nDrama (513)\nAction (303)\nComedy (279)\nAdventure (259)\n```\n\nTheory:\n\nWhen an operation is giving you a sequence of sequences like:\n\n```scala\nArray(\"hello\", \"world\").map(word => word.split(\"\"))\nres91: Array[Array[String]] = Array(Array(h, e, l, l, o), Array(w, o, r, l, d))\n```\n\nYou may want to flatten this to only have a single list like:\n```scala\nArray(\"hello\", \"world\").map(_.split(\"\")).flatten\nres93: Array[String] = Array(h, e, l, l, o, w, o, r, l, d)\n```\n\nYou can achieve the same result (i.e. `map` + `flatten`) using `flatMap`:\n```scala\nArray(\"hello\", \"world\").flatMap(_.split(\"\"))\nres95: Array[String] = Array(h, e, l, l, o, w, o, r, l, d)\n```\n\nWe are going to apply this same technique with the `genres` member.\n\nSteps:\n\n* Use `flatMap()` to get the list with all the genres\n* Make sure to remove trailling whitespaces\n* Count the genres\n* Sort them by decreasing order\n* Show the top 10 genres",
      "user": "anonymous",
      "dateUpdated": "2024-05-24T08:08:05+0000",
      "progress": 0,
      "config": {
        "lineNumbers": true,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "colWidth": 12,
        "editorHide": true,
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h4>Ex3 - Print the 10 top genres</h4>\n<p>Goals:</p>\n<ul>\n<li>Print the list of the genres that appears the most</li>\n<li>Use <code>flatMap()</code></li>\n</ul>\n<p>Output example:</p>\n<pre><code class=\"language-plain\">Drama (513)\nAction (303)\nComedy (279)\nAdventure (259)\n</code></pre>\n<p>Theory:</p>\n<p>When an operation is giving you a sequence of sequences like:</p>\n<pre><code class=\"language-scala\">Array(&quot;hello&quot;, &quot;world&quot;).map(word =&gt; word.split(&quot;&quot;))\nres91: Array[Array[String]] = Array(Array(h, e, l, l, o), Array(w, o, r, l, d))\n</code></pre>\n<p>You may want to flatten this to only have a single list like:</p>\n<pre><code class=\"language-scala\">Array(&quot;hello&quot;, &quot;world&quot;).map(_.split(&quot;&quot;)).flatten\nres93: Array[String] = Array(h, e, l, l, o, w, o, r, l, d)\n</code></pre>\n<p>You can achieve the same result (i.e. <code>map</code> + <code>flatten</code>) using <code>flatMap</code>:</p>\n<pre><code class=\"language-scala\">Array(&quot;hello&quot;, &quot;world&quot;).flatMap(_.split(&quot;&quot;))\nres95: Array[String] = Array(h, e, l, l, o, w, o, r, l, d)\n</code></pre>\n<p>We are going to apply this same technique with the <code>genres</code> member.</p>\n<p>Steps:</p>\n<ul>\n<li>Use <code>flatMap()</code> to get the list with all the genres</li>\n<li>Make sure to remove trailling whitespaces</li>\n<li>Count the genres</li>\n<li>Sort them by decreasing order</li>\n<li>Show the top 10 genres</li>\n</ul>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1716538085687_809272930",
      "id": "20240513-092648_1323552940",
      "dateCreated": "2024-05-24T08:08:05+0000",
      "status": "READY",
      "$$hashKey": "object:196"
    },
    {
      "text": "%spark\nval top10Genres = rddMovies.flatMap(m => m.genres).map(_.trim).map((_, 1)).reduceByKey(_ + _).sortBy({ case (_, count) => count }, ascending = false).take(10)\ntop10Genres.foreach { case (genre, count) =>\n  println(s\"$genre ($count)\")\n}",
      "user": "anonymous",
      "dateUpdated": "2024-05-24T09:00:46+0000",
      "progress": 0,
      "config": {
        "lineNumbers": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "colWidth": 12,
        "editorHide": false,
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "Drama (513)\nAction (303)\nComedy (279)\nAdventure (259)\nThriller (195)\nCrime (150)\nRomance (141)\nSci-Fi (120)\nHorror (119)\nMystery (106)\nval \u001b[1m\u001b[34mtop10Genres\u001b[0m: \u001b[1m\u001b[32mArray[(String, Int)]\u001b[0m = Array((Drama,513), (Action,303), (Comedy,279), (Adventure,259), (Thriller,195), (Crime,150), (Romance,141), (Sci-Fi,120), (Horror,119), (Mystery,106))\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://47152b476fc3:4040/jobs/job?id=12",
              "$$hashKey": "object:3127"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1716538085687_1915753497",
      "id": "20240513-092648_877853710",
      "dateCreated": "2024-05-24T08:08:05+0000",
      "status": "FINISHED",
      "$$hashKey": "object:197",
      "dateFinished": "2024-05-24T09:00:47+0000",
      "dateStarted": "2024-05-24T09:00:47+0000"
    },
    {
      "text": "%md\n#### Ex4 - Print the average number of votes per year, order by descreasing number of votes\n\nGoal:\n\n* Print the average votes per year\n* This output is sorted by descreasing votes\n\nOutput example:\n\n```plain\n...\nyear: 2008 average votes: 275505.3846153846\nyear: 2009 average votes: 255780.64705882352\nyear: 2010 average votes: 252782.31666666668\n...\n```\n\nTheory:\n\nWe are going to use `reduceByKey()` which has the following signature `reduceByKey(func: (V, V) => V): RDD[(K, V)]`. \n\n`reduceByKey()` works on a RDD like `RDD[(K,V)]` (i.e. sort of \"list of key/values pairs\"). \n\n`reduceByKey()` takes a function that, from two elements, returns one i.e. the `func: (V, V) => V` in the signature.\nThe difference with `reduce()` is that `reduceByKey()` uses two elements sharing the same key.\n\nFor example (pseudo code):\n\n```plain\n year, count\n(2010, 2)\n(2011, 3)\n(2011, 4)\n(2010, 8)\n// use reduceByKey((count1, count2) => count1+count2)\n> (2010, 10)\n> (2011, 7)\n```\n\nNote: here `count` is just an Int but it can be anything e.g. `Movie`\n\nSteps:\n\n* To compute the average we need the **total sum** of votes per year and the **count** of all the movies per year\n* Use `map()` to create an RDD made of `(year, (votes, 1))`. Like a word count we use the `1` to be able to count the number of movies per year\n* Use `reduceByKey()` to sum the votes and to count the number of movies per year. The output should look like: `(year, (totalVotes, moviePerYearCount))`\n* Find a way to compute the average using the result from the last operation\n* Sort by number of votes decreasing",
      "user": "anonymous",
      "dateUpdated": "2024-05-24T08:08:05+0000",
      "progress": 0,
      "config": {
        "lineNumbers": true,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "colWidth": 12,
        "editorHide": true,
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h4>Ex4 - Print the average number of votes per year, order by descreasing number of votes</h4>\n<p>Goal:</p>\n<ul>\n<li>Print the average votes per year</li>\n<li>This output is sorted by descreasing votes</li>\n</ul>\n<p>Output example:</p>\n<pre><code class=\"language-plain\">...\nyear: 2008 average votes: 275505.3846153846\nyear: 2009 average votes: 255780.64705882352\nyear: 2010 average votes: 252782.31666666668\n...\n</code></pre>\n<p>Theory:</p>\n<p>We are going to use <code>reduceByKey()</code> which has the following signature <code>reduceByKey(func: (V, V) =&gt; V): RDD[(K, V)]</code>.</p>\n<p><code>reduceByKey()</code> works on a RDD like <code>RDD[(K,V)]</code> (i.e. sort of &ldquo;list of key/values pairs&rdquo;).</p>\n<p><code>reduceByKey()</code> takes a function that, from two elements, returns one i.e. the <code>func: (V, V) =&gt; V</code> in the signature.<br />\nThe difference with <code>reduce()</code> is that <code>reduceByKey()</code> uses two elements sharing the same key.</p>\n<p>For example (pseudo code):</p>\n<pre><code class=\"language-plain\"> year, count\n(2010, 2)\n(2011, 3)\n(2011, 4)\n(2010, 8)\n// use reduceByKey((count1, count2) =&gt; count1+count2)\n&gt; (2010, 10)\n&gt; (2011, 7)\n</code></pre>\n<p>Note: here <code>count</code> is just an Int but it can be anything e.g. <code>Movie</code></p>\n<p>Steps:</p>\n<ul>\n<li>To compute the average we need the <strong>total sum</strong> of votes per year and the <strong>count</strong> of all the movies per year</li>\n<li>Use <code>map()</code> to create an RDD made of <code>(year, (votes, 1))</code>. Like a word count we use the <code>1</code> to be able to count the number of movies per year</li>\n<li>Use <code>reduceByKey()</code> to sum the votes and to count the number of movies per year. The output should look like: <code>(year, (totalVotes, moviePerYearCount))</code></li>\n<li>Find a way to compute the average using the result from the last operation</li>\n<li>Sort by number of votes decreasing</li>\n</ul>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1716538085687_1725738211",
      "id": "20240513-092648_1078439886",
      "dateCreated": "2024-05-24T08:08:05+0000",
      "status": "READY",
      "$$hashKey": "object:198"
    },
    {
      "text": "%spark\nval votesPerYear = rddMovies.map(m => (m.year, (m.votes, 1)))\ndef sumCounts(a: (Int, Int), b: (Int, Int)): (Int, Int) = {\n  val (votes1, count1) = a\n  val (votes2, count2) = b\n  (votes1 + votes2, count1 + count2)\n}\n\nval totalVotesAndCountPerYear = votesPerYear.reduceByKey(sumCounts)\nval averageVotesPerYear = totalVotesAndCountPerYear.map { case (year, (totalVotes, movieCount)) =>\n  (year, totalVotes.toDouble / movieCount)\n}\n\nval sortedAverageVotesPerYear = averageVotesPerYear.sortBy(_._2, ascending = false)\nsortedAverageVotesPerYear.collect().foreach { case (year, avgVotes) =>\n  println(f\"year: $year average votes: $avgVotes%.10f\")\n}\n",
      "user": "anonymous",
      "dateUpdated": "2024-05-24T09:07:28+0000",
      "progress": 0,
      "config": {
        "lineNumbers": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "colWidth": 12,
        "editorHide": false,
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "year: 2012 average votes: 285226.0937500000\nyear: 2008 average votes: 275505.3846153846\nyear: 2006 average votes: 269289.9545454545\nyear: 2009 average votes: 255780.6470588235\nyear: 2010 average votes: 252782.3166666667\nyear: 2007 average votes: 244331.0377358491\nyear: 2011 average votes: 240790.3015873016\nyear: 2013 average votes: 219049.6483516484\nyear: 2014 average votes: 203930.2244897959\nyear: 2015 average votes: 115726.2204724409\nyear: 2016 average votes: 48591.7542087542\nval \u001b[1m\u001b[34mvotesPerYear\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.rdd.RDD[(Int, (Int, Int))]\u001b[0m = MapPartitionsRDD[58] at map at <console>:2\ndef sumCounts(a: (Int, Int), b: (Int, Int)): \u001b[1m\u001b[32m(Int, Int)\u001b[0m\nval \u001b[1m\u001b[34mtotalVotesAndCountPerYear\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.rdd.RDD[(Int, (Int, Int))]\u001b[0m = ShuffledRDD[59] at reduceByKey at <console>:9\nval \u001b[1m\u001b[34maverageVotesPerYear\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.rdd.RDD[(Int, Double)]\u001b[0m = MapPartitionsRDD[60] at map at <console>:10\nval \u001b[1m\u001b[34msortedAverageVotesPerYear\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.rdd.RDD[(Int, Double)]\u001b[0m = MapPartitionsRDD[63] at sortBy at <console>:14\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://47152b476fc3:4040/jobs/job?id=15",
              "$$hashKey": "object:3278"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1716538085687_1716140272",
      "id": "20240513-092648_1308721736",
      "dateCreated": "2024-05-24T08:08:05+0000",
      "status": "FINISHED",
      "$$hashKey": "object:199",
      "dateFinished": "2024-05-24T09:07:28+0000",
      "dateStarted": "2024-05-24T09:07:28+0000"
    },
    {
      "text": "%md\n### Part 2 - Create a basic Inverted Index\n\nThe goal of this part is to show you how to create an inverted index that indexes words from all the movies' description.",
      "user": "anonymous",
      "dateUpdated": "2024-05-24T08:08:05+0000",
      "progress": 0,
      "config": {
        "lineNumbers": true,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "colWidth": 12,
        "editorHide": true,
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h3>Part 2 - Create a basic Inverted Index</h3>\n<p>The goal of this part is to show you how to create an inverted index that indexes words from all the movies&rsquo; description.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1716538085687_193549036",
      "id": "20240513-092648_362503434",
      "dateCreated": "2024-05-24T08:08:05+0000",
      "status": "READY",
      "$$hashKey": "object:200"
    },
    {
      "text": "%md\nGoal:\n\nUsing `rddMovies` create an inverted that use the movies' description:\n\n```plain\nMovie(1,Guardians of the Galaxy,List(Action, Adventure, Sci-Fi),A group of intergalactic [...] of the universe.,James Gunn,List(Chris Pratt, Vin Diesel, Bradley Cooper, Zoe Saldana),2014,8.1,757074.0)\nMovie(2,Prometheus,List(Adventure, Mystery, Sci-Fi),Following clues to the origin[...] not alone.,Ridley Scott,List(Noomi Rapace, Logan Marshall-Green, Michael Fassbender, Charlize Theron),2012,7.0,485820.0)\nMovie(3,Split,List(Horror, Thriller),Three girls are kidnapped [...] a frightful new 24th.,M. Night Shyamalan,List(James McAvoy, Anya Taylor-Joy, Haley Lu Richardson, Jessica Sula),2016,7.3,157606.0)\n...\n```\n\nand extract them to produce an inverted index like:\n\n```plain\n\"reunion\" -> (640, 697)\n\"runner\" -> (338)\n\"vietnam\" -> (797, 947, 983)\n...\n```\n\nSteps\n\n* Tokenize description i.e. produce an RDD like (movId, words)\n* Normalize words e.g. toLowercase, trimming,..\n* Remove stopwords (ignored here)\n* Apply stemming (ignored here)\n* Group by document id",
      "user": "anonymous",
      "dateUpdated": "2024-05-24T08:08:05+0000",
      "progress": 0,
      "config": {
        "lineNumbers": true,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "colWidth": 12,
        "editorHide": true,
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>Goal:</p>\n<p>Using <code>rddMovies</code> create an inverted that use the movies&rsquo; description:</p>\n<pre><code class=\"language-plain\">Movie(1,Guardians of the Galaxy,List(Action, Adventure, Sci-Fi),A group of intergalactic [...] of the universe.,James Gunn,List(Chris Pratt, Vin Diesel, Bradley Cooper, Zoe Saldana),2014,8.1,757074.0)\nMovie(2,Prometheus,List(Adventure, Mystery, Sci-Fi),Following clues to the origin[...] not alone.,Ridley Scott,List(Noomi Rapace, Logan Marshall-Green, Michael Fassbender, Charlize Theron),2012,7.0,485820.0)\nMovie(3,Split,List(Horror, Thriller),Three girls are kidnapped [...] a frightful new 24th.,M. Night Shyamalan,List(James McAvoy, Anya Taylor-Joy, Haley Lu Richardson, Jessica Sula),2016,7.3,157606.0)\n...\n</code></pre>\n<p>and extract them to produce an inverted index like:</p>\n<pre><code class=\"language-plain\">&quot;reunion&quot; -&gt; (640, 697)\n&quot;runner&quot; -&gt; (338)\n&quot;vietnam&quot; -&gt; (797, 947, 983)\n...\n</code></pre>\n<p>Steps</p>\n<ul>\n<li>Tokenize description i.e. produce an RDD like (movId, words)</li>\n<li>Normalize words e.g. toLowercase, trimming,..</li>\n<li>Remove stopwords (ignored here)</li>\n<li>Apply stemming (ignored here)</li>\n<li>Group by document id</li>\n</ul>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1716538085687_1716399663",
      "id": "20240513-092648_1212054958",
      "dateCreated": "2024-05-24T08:08:05+0000",
      "status": "READY",
      "$$hashKey": "object:201"
    },
    {
      "text": "%spark\n/**\n* Goal: create an inverted index that allows searching a word\n* in the movies description.\n* Features:\n* - case insensitive\n*\n*/\n\n// In this first function we are going to tokenize and order the descriptions of the movies, then return these data. We are not going to apply any search right now.\ndef createInvertedIndex(movies: RDD[Movie]): RDD[(String, Iterable[Int])] = {\n    // Define helper functions directly inside this function. In scala you can declare inner functions\n    // and use them only inside the function they were declared. Useful to encapsulate/restrict \n    // their use outside this function.\n    \n    // Split the given string into an array of words (without any formatting), then return it.\n    def tokenizeDescription(description: String): Seq[String] = {\n        description.split(\"\\\\W+\").filter(_.nonEmpty)\n    }\n    \n    // Remove the blank spaces (trim) in the given word, transform it in lowercase, then return it.\n    def normalizeWord(word: String): String = {\n        word.toLowerCase()\n    }\n    \n    // For the sake of simplicity let's ignore the implementation (in a real case we would return true if w is a stopword, otherwise false).\n    def isStopWord(w: String): Boolean = {\n        false\n    }\n    \n    // For the sake of simplicity let's ignore the implementation (in a real case we would apply stemming to w and return the result, e.g. w=automation -> w=automat).\n    def applyStemming(w: String): String = {\n        w\n    }\n    \n    // Tokenize and normalize each movie's description, then create key-value pairs (word, movie ID)\n    val tokenizedMovies = movies.flatMap(movie => {\n        val movieId = movie.id\n        val words = tokenizeDescription(movie.description)\n        words.map(word => (normalizeWord(word), movieId))\n    })\n    \n    // TODO\n    // Here we are going to work on the movies RDD, by tokenizing and normalizing the description of every movie, then by building a key-value object that contains the tokens as keys, and the IDs of the movies as values\n    // (see the example on 4).\n    // The goal here is to do everything by chaining the possible transformations and actions of Spark.\n    // Possible steps:\n    //   1) What we first want to do here is applying the 4 previous methods on any movie's description. Be aware of the fact that we also want to keep the IDs of the movies.\n    //   2) For each tokenized word, create a tuple as (word, id), where id is the current movie id\n    //        [\n    //          (\"toto\", 120), (\"mange\", 120), (\"des\", 120), (\"pommes\", 120),\n    //          (\"toto\", 121), (\"lance\", 121), (\"des\", 121), (\"photocopies\", 121)\n    //        ]\n    //      Hint: you can use a `map` function inside another `map` function.\n    //   3) We finally need to find a way to remove duplicated keys and thus only having one entry per key, with all the linked IDs as values. For example:\n    //        [\n    //          (\"toto\", [120, 121]),\n    //          (\"mange\", [120]),\n    //          ...\n    //        ]\n    val invertedIndex = tokenizedMovies.groupByKey().mapValues(_.toIterable)\n\n    // Return the new-built inverted index.\n    invertedIndex\n}",
      "user": "anonymous",
      "dateUpdated": "2024-05-24T09:19:57+0000",
      "progress": 0,
      "config": {
        "lineNumbers": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "colWidth": 12,
        "editorHide": false,
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[33mwarning: \u001b[0m1 deprecation (since 2.13.0)\n\u001b[33mwarning: \u001b[0m1 deprecation (since 2.13.7)\n\u001b[33mwarning: \u001b[0m2 deprecations in total; for details, enable `:setting -deprecation` or `:replay -deprecation`\ndef createInvertedIndex(movies: org.apache.spark.rdd.RDD[Movie]): \u001b[1m\u001b[32morg.apache.spark.rdd.RDD[(String, Iterable[Int])]\u001b[0m\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1716538085687_279227174",
      "id": "20240513-092648_1408148244",
      "dateCreated": "2024-05-24T08:08:05+0000",
      "status": "FINISHED",
      "$$hashKey": "object:202",
      "dateFinished": "2024-05-24T09:19:57+0000",
      "dateStarted": "2024-05-24T09:19:57+0000"
    },
    {
      "text": "%md\nNow we would like to use our inverted index to display the top N most used words in the descriptions of movies.",
      "user": "anonymous",
      "dateUpdated": "2024-05-24T08:08:05+0000",
      "progress": 0,
      "config": {
        "lineNumbers": true,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "colWidth": 12,
        "editorHide": true,
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>Now we would like to use our inverted index to display the top N most used words in the descriptions of movies.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1716538085687_1510738706",
      "id": "20240513-092648_1571732340",
      "dateCreated": "2024-05-24T08:08:05+0000",
      "status": "READY",
      "$$hashKey": "object:203"
    },
    {
      "text": "%spark\n// Here we are going to operate the analytic and display its result on a given inverted index (that will be obtained from the previous function).\ndef topN(invertedIndex: RDD[(String, Iterable[Int])], N: Int): Unit = {\n    \n  val wordCounts = invertedIndex.mapValues(_.size)\n  \n  val sortedWordCounts = wordCounts.sortBy(-_._2)\n  \n  // We are going to work on the given invertedIndex array to do our analytic:\n  //   1) Find a way to get the number of movie in which a word appears.\n  //   2) Keep only the top N words and their occurence.\n  val topWords: Array[(String, Int)] = sortedWordCounts.take(N)\n  \n  // Print the words and the number of descriptions in which they appear.\n  println(\"Top '\" + N + \"' most used words\")\n  topWords.foreach(println)\n}",
      "user": "anonymous",
      "dateUpdated": "2024-05-24T09:21:23+0000",
      "progress": 0,
      "config": {
        "lineNumbers": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "colWidth": 12,
        "editorHide": false,
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "def topN(invertedIndex: org.apache.spark.rdd.RDD[(String, Iterable[Int])], N: Int): \u001b[1m\u001b[32mUnit\u001b[0m\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1716538085687_1139291880",
      "id": "20240513-092648_800469110",
      "dateCreated": "2024-05-24T08:08:05+0000",
      "status": "FINISHED",
      "$$hashKey": "object:204",
      "dateFinished": "2024-05-24T09:21:23+0000",
      "dateStarted": "2024-05-24T09:21:23+0000"
    },
    {
      "text": "%spark\n// Code used to test your implementation.\n// Create the inverted index of the movies.\nval invertedIndex = createInvertedIndex(rddMovies)\n\n// Show how the inverted index looks like.\ninvertedIndex.take(3).foreach(x => println(x._1 + \": \" + x._2.mkString(\", \")))\n\n// Show the top 10 most used words.\ntopN(invertedIndex, 10)",
      "user": "anonymous",
      "dateUpdated": "2024-05-24T09:21:37+0000",
      "progress": 0,
      "config": {
        "lineNumbers": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "colWidth": 12,
        "editorHide": false,
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "divorcee: 63\nreunion: 640, 697\nconfidants: 785\nTop '10' most used words\n(a,1640)\n(the,1364)\n(to,938)\n(of,814)\n(and,721)\n(in,580)\n(his,487)\n(an,304)\n(is,296)\n(with,274)\nval \u001b[1m\u001b[34minvertedIndex\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.rdd.RDD[(String, Iterable[Int])]\u001b[0m = MapPartitionsRDD[66] at mapValues at <console>:61\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://47152b476fc3:4040/jobs/job?id=16",
              "$$hashKey": "object:3407"
            },
            {
              "jobUrl": "http://47152b476fc3:4040/jobs/job?id=17",
              "$$hashKey": "object:3408"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1716538085687_766937402",
      "id": "20240513-092648_1232697535",
      "dateCreated": "2024-05-24T08:08:05+0000",
      "status": "FINISHED",
      "$$hashKey": "object:205",
      "dateFinished": "2024-05-24T09:21:37+0000",
      "dateStarted": "2024-05-24T09:21:37+0000"
    },
    {
      "text": "%spark\n",
      "user": "anonymous",
      "dateUpdated": "2024-05-24T08:08:05+0000",
      "progress": 0,
      "config": {
        "lineNumbers": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "colWidth": 12,
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": []
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1716538085688_346514279",
      "id": "paragraph_1716290266344_470791481",
      "dateCreated": "2024-05-24T08:08:05+0000",
      "status": "READY",
      "$$hashKey": "object:206"
    }
  ],
  "name": "MAC-Lab-SparkRDDs",
  "id": "2JYM51H4D",
  "defaultInterpreterGroup": "spark",
  "version": "0.11.0",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false,
    "looknfeel": "default",
    "personalizedMode": "false"
  },
  "info": {},
  "path": "/MAC-Lab-SparkRDDs"
}